{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>996009318</td>\n",
       "      <td>THE LIONS CLUB OF HONOLULU KAMEHAMEHA</td>\n",
       "      <td>T4</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>996010315</td>\n",
       "      <td>INTERNATIONAL ASSOCIATION OF LIONS CLUBS</td>\n",
       "      <td>T4</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>996012607</td>\n",
       "      <td>PTA HAWAII CONGRESS</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>996015768</td>\n",
       "      <td>AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...</td>\n",
       "      <td>T5</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>996086871</td>\n",
       "      <td>WATERHOUSE CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1M-5M</td>\n",
       "      <td>N</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             EIN                                               NAME  \\\n",
       "0       10520599                       BLUE KNIGHTS MOTORCYCLE CLUB   \n",
       "1       10531628             AMERICAN CHESAPEAKE CLUB CHARITABLE TR   \n",
       "2       10547893                 ST CLOUD PROFESSIONAL FIREFIGHTERS   \n",
       "3       10553066                     SOUTHSIDE ATHLETIC ASSOCIATION   \n",
       "4       10556103           GENETIC RESEARCH INSTITUTE OF THE DESERT   \n",
       "...          ...                                                ...   \n",
       "34294  996009318              THE LIONS CLUB OF HONOLULU KAMEHAMEHA   \n",
       "34295  996010315           INTERNATIONAL ASSOCIATION OF LIONS CLUBS   \n",
       "34296  996012607                                PTA HAWAII CONGRESS   \n",
       "34297  996015768  AMERICAN FEDERATION OF GOVERNMENT EMPLOYEES LO...   \n",
       "34298  996086871                           WATERHOUSE CHARITABLE TR   \n",
       "\n",
       "      APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0                  T10       Independent          C1000    ProductDev   \n",
       "1                   T3       Independent          C2000  Preservation   \n",
       "2                   T5  CompanySponsored          C3000    ProductDev   \n",
       "3                   T3  CompanySponsored          C2000  Preservation   \n",
       "4                   T3       Independent          C1000     Heathcare   \n",
       "...                ...               ...            ...           ...   \n",
       "34294               T4       Independent          C1000    ProductDev   \n",
       "34295               T4  CompanySponsored          C3000    ProductDev   \n",
       "34296               T3  CompanySponsored          C2000  Preservation   \n",
       "34297               T5       Independent          C3000    ProductDev   \n",
       "34298               T3       Independent          C1000  Preservation   \n",
       "\n",
       "       ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS   ASK_AMT  \\\n",
       "0       Association       1              0                      N      5000   \n",
       "1      Co-operative       1         1-9999                      N    108590   \n",
       "2       Association       1              0                      N      5000   \n",
       "3             Trust       1    10000-24999                      N      6692   \n",
       "4             Trust       1  100000-499999                      N    142590   \n",
       "...             ...     ...            ...                    ...       ...   \n",
       "34294   Association       1              0                      N      5000   \n",
       "34295   Association       1              0                      N      5000   \n",
       "34296   Association       1              0                      N      5000   \n",
       "34297   Association       1              0                      N      5000   \n",
       "34298  Co-operative       1          1M-5M                      N  36500179   \n",
       "\n",
       "       IS_SUCCESSFUL  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  1  \n",
       "...              ...  \n",
       "34294              0  \n",
       "34295              0  \n",
       "34296              0  \n",
       "34297              1  \n",
       "34298              0  \n",
       "\n",
       "[34299 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "\n",
    "\n",
    "# Read in our ramen data\n",
    "charity_df = pd.read_csv(\"charity_data.csv\")\n",
    "# Read in our ramen data\n",
    "charity_df\n",
    "# # Print out the Country value counts\n",
    "# country_counts = ramen_df.Country.value_counts()\n",
    "# country_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34299 entries, 0 to 34298\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   EIN                     34299 non-null  int64 \n",
      " 1   NAME                    34299 non-null  object\n",
      " 2   APPLICATION_TYPE        34299 non-null  object\n",
      " 3   AFFILIATION             34299 non-null  object\n",
      " 4   CLASSIFICATION          34299 non-null  object\n",
      " 5   USE_CASE                34299 non-null  object\n",
      " 6   ORGANIZATION            34299 non-null  object\n",
      " 7   STATUS                  34299 non-null  int64 \n",
      " 8   INCOME_AMT              34299 non-null  object\n",
      " 9   SPECIAL_CONSIDERATIONS  34299 non-null  object\n",
      " 10  ASK_AMT                 34299 non-null  int64 \n",
      " 11  IS_SUCCESSFUL           34299 non-null  int64 \n",
      "dtypes: int64(4), object(8)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "charity_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# charity_df.hvplot(kind=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>EIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>10520599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>10531628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>10547893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>10553066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>10556103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       NAME       EIN\n",
       "0              BLUE KNIGHTS MOTORCYCLE CLUB  10520599\n",
       "1    AMERICAN CHESAPEAKE CLUB CHARITABLE TR  10531628\n",
       "2        ST CLOUD PROFESSIONAL FIREFIGHTERS  10547893\n",
       "3            SOUTHSIDE ATHLETIC ASSOCIATION  10553066\n",
       "4  GENETIC RESEARCH INSTITUTE OF THE DESERT  10556103"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coins_name_df = pd.DataFrame(df_crypto[\"CoinName\"])\n",
    "# coins_name_df.head()\n",
    "\n",
    "charity_names_df = pd.DataFrame(charity_df[[\"NAME\",\"EIN\"]])\n",
    "charity_names_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NAME', 'EIN']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_list= list(charity_df[[\"NAME\",\"EIN\"]])\n",
    "drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(drop_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## drop name column as not needed \n",
    "\n",
    "charity_df = charity_df.drop(drop_list,axis=1)\n",
    "charity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no longer using EIN as index to keep original index to be able to merge later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EIN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10520599</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10531628</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10547893</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10553066</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10556103</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "EIN                                                                        \n",
       "10520599              T10       Independent          C1000    ProductDev   \n",
       "10531628               T3       Independent          C2000  Preservation   \n",
       "10547893               T5  CompanySponsored          C3000    ProductDev   \n",
       "10553066               T3  CompanySponsored          C2000  Preservation   \n",
       "10556103               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "          ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "EIN                                                                             \n",
       "10520599   Association       1              0                      N     5000   \n",
       "10531628  Co-operative       1         1-9999                      N   108590   \n",
       "10547893   Association       1              0                      N     5000   \n",
       "10553066         Trust       1    10000-24999                      N     6692   \n",
       "10556103         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "          IS_SUCCESSFUL  \n",
       "EIN                      \n",
       "10520599              1  \n",
       "10531628              1  \n",
       "10547893              0  \n",
       "10553066              1  \n",
       "10556103              1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# charity_df = charity_df.set_index(\"EIN\")\n",
    "# charity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10520599</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10531628</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10547893</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10553066</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10556103</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "10520599              T10       Independent          C1000    ProductDev   \n",
       "10531628               T3       Independent          C2000  Preservation   \n",
       "10547893               T5  CompanySponsored          C3000    ProductDev   \n",
       "10553066               T3  CompanySponsored          C2000  Preservation   \n",
       "10556103               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "          ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "10520599   Association       1              0                      N     5000   \n",
       "10531628  Co-operative       1         1-9999                      N   108590   \n",
       "10547893   Association       1              0                      N     5000   \n",
       "10553066         Trust       1    10000-24999                      N     6692   \n",
       "10556103         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "          IS_SUCCESSFUL  \n",
       "10520599              1  \n",
       "10531628              1  \n",
       "10547893              0  \n",
       "10553066              1  \n",
       "10556103              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #remove ein name from index to be used for all df needed to be split or recreated \n",
    "\n",
    "# charity_df.index.name = None\n",
    "# charity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_consid = charity_df[\"SPECIAL_CONSIDERATIONS\"].unique()\n",
    "unq_consid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable list\n",
    "charity_cat = charity_df.dtypes[charity_df.dtypes == \"object\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charity_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE          17\n",
       "AFFILIATION                6\n",
       "CLASSIFICATION            71\n",
       "USE_CASE                   5\n",
       "ORGANIZATION               4\n",
       "INCOME_AMT                 9\n",
       "SPECIAL_CONSIDERATIONS     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attrition_df[attrition_cat].nunique()\n",
    "#check # of unq val in each column \n",
    "charity_df[charity_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droped name column , need to pick what to do with application type and classification \n",
    "#check unique in each column and choose to set other or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column APPLICATION_TYPE has 0 null values\n",
      "column AFFILIATION has 0 null values\n",
      "column CLASSIFICATION has 0 null values\n",
      "column USE_CASE has 0 null values\n",
      "column ORGANIZATION has 0 null values\n",
      "column STATUS has 0 null values\n",
      "column INCOME_AMT has 0 null values\n",
      "column SPECIAL_CONSIDERATIONS has 0 null values\n",
      "column ASK_AMT has 0 null values\n",
      "column IS_SUCCESSFUL has 0 null values\n"
     ]
    }
   ],
   "source": [
    "## finding how many nulls are in there to be able to drop those rows \n",
    "for column in charity_df.columns:\n",
    "    print(f\"column {column} has {charity_df[column].isnull().sum()} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start binning application types down to top ten \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['T10', 'T3', 'T5', 'T7', 'T4', 'T6', 'T2', 'T9', 'T19', 'T8',\n",
       "       'T13', 'T12', 'T29', 'T25', 'T14', 'T17', 'T15'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charity_df['APPLICATION_TYPE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_app_type = charity_df['APPLICATION_TYPE'].value_counts()\n",
    "counts_app_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc2e1939a50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD4CAYAAAA6j0u4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxd1ZXg+9+692qercEabQtPsmxsBmFCICmDSTAQcNJFKqY6VXQ3Xel+gUrlUa86kMpLp6miukhehXr5PJIKnVQ3SVcChFDBEAMZmBJG2xjPki3PsiRb8zzf9f64R0YWV9ZgnXvusL4f7odz99ln37VlSUtnn332EVXFGGOMcZPP6wCMMcbEP0s2xhhjXGfJxhhjjOss2RhjjHGdJRtjjDGuC3gdQDQqKCjQJUuWeB2GMcbElJ07d7aqamG4fZZswliyZAk7duzwOgxjjIkpInJiqn02jGaMMcZ1lmyMMca4zpKNMcYY11myMcYY4zpLNsYYY1xnycYYY4zrLNkYY4xxnd1nYzx3oq2Pl/Y3kxLwc/OaYoqyU70OyRgzz1w9sxGRTSJSJyL1InJ/mP0pIvKks/8dEVkyYd8DTnmdiNw0XZsicq9TpiJSMKFcROQ7zr49InKFez02s/WD3x3lhn94jb/bVst/3bqfjf/wGr/a3+x1WMaYeeZashERP/AocDNQDdwpItWTqt0NdKjqMuAR4GHn2GpgC7Aa2AR8V0T807T5BnAjMPkO1puB5c7rC8D35rOfZu5+/PYJ/vaXB/nEqoW89cAN/Oa+P+CSwgzu+cl7vHWkzevwjDHzyM0zm/VAvaoeVdVh4Alg86Q6m4HHne2ngY0iIk75E6o6pKrHgHqnvSnbVNVdqno8TBybgR9pyNtAroiUzGtPzawdOtPD3zx3gA0rC3n0315BSU4ay4oy+dHdV7NoQTpffnIX3YMjXodpjJknbiabMuDUhPcNTlnYOqo6CnQB+Rc4diZtziUOROQLIrJDRHa0tLRM06S5GKrKN7buJy3Zz7f/6DL8Pjm3LyctiW//0WW09Azx7V8d8jBKY8x8cjPZSJgynWGd2ZZfbByo6mOqWqOqNYWFYRctNfPkjfo23jzSxn2fWMGCjOQP7V9XkcvnrqrgJ++c5HTngAcRGmPmm5vJpgGomPC+HGicqo6IBIAcoP0Cx86kzbnEYSLo+68foTArhS3rK6asc+8Ny1GU//H60QhGZoxxi5vJZjuwXEQqRSSZ0AX/rZPqbAXucrbvAF5WVXXKtziz1SoJXdx/d4ZtTrYV+FNnVtpHgC5VbZqPDprZ29/Yxe8Ot/Ifrq0kJeCfsl5Zbhq3XlrCz3c20Dc0GsEIjTFucC3ZONdg7gVeAg4CT6nqfhF5UERud6r9EMgXkXrgPuB+59j9wFPAAeBF4B5VHZuqTQAR+ZKINBA6c9kjIj9wPmMbcJTQJIP/AXzRrT6b6f303ZOkBHz88dWLpq37J9csoWdolH/ddToCkRlj3CShEwkzUU1NjdrD0+bf4MgY6x/6DTdUFfGPWy6ftr6qcut3fo/PB8//+cciEKEx5mKIyE5VrQm3z5arMRHz6wNn6B4c5Y4rp75WM5GI8G+uKGPf6W6OtvS6HJ0xxk2WbEzEPLe7keLsVD66NH/Gx3xqbSkisHW3zekwJpZZsjERMTA8xuuHW7hp9UJ8vnCz0cMrzkll/ZIFbN3diA35GhO7LNmYiHj9cAuDI0E+ubp41sfeuraEoy19HG3tcyEyY0wkWLIxEfHS/mZy0pJYX7lg1sfeUFUEwCu1Z+c7LGNMhFiyMa4bHQvycu1ZNlYVkeSf/bdceV46Kxdm8duDlmyMiVWWbIzrdjd00dk/wsZVC+fcxvVVRWw/3m6LcxoToyzZGNe9Ud+KCLOahTbZxlVFjAaV3x1qncfIjDGRYsnGuO739a2sKc0hL8yimzN1eUUuWakBfl9vK3IbE4ss2RhX9Q+PsutkB9cuK5i+8gUE/D6ursznTXuomjExyZKNcdW7x9oZGVOuu8hkA6FhuBNt/fbYAWNikCUb46o36ltJDvioWZJ30W1d41zzsUdGGxN7LNkYV/2+vo2axXmkJk39OIGZWrkwi7z0JEs2xsQgSzbGNV0DI9Q2d/ORS+Y+C20in0+4Zmk+bx1ptaVrjIkxlmyMa9472YEq8zKENu7qynwauwZp7BqctzaNMe6zZGNcs/N4B36fcFlF7ry1eeXiUOLaeaJj3to0xrjPko1xzY4T7VSXZJOeHJi3NquKs0hP9vOeJRtjYoolG+OKkbEg75/qPHcmMl8Cfh+XVeTamY0xMcaSjXHF/sZuBkeC83q9ZtyVi/M40NRN//DovLdtjHGHJRvjih3H2wGoWTz7RwpM54rFeYwFlfdPdc5728YYd1iyMa5472QHZblpFOekznvbV1SEzpbsuo0xscOSjXHF+yc7uXzR/M1CmygnPYnlRZnssGRjTMywZGPmXUvPEI1dg6wrdyfZAFy+KJfdpzrt5k5jYoQlGzPv9p3uAuDS8hzXPmNteS4d/SM0dNiinMbEAks2Zt7tbuhEBNaUuZlsQm3vdRKbMSa6WbIx825vQxdLCzPJTJm/mzknW1mcRbLfx54GSzbGxAJLNmZeqSq7G7rOnXm4JSXgp6okiz0NNv3ZmFhgycbMq+buQVp7h1jr4hDauEvLcth7uotg0CYJGBPtLNmYebX7VGhYa+08Lr45lbXlOfQMjnKivd/1zzLGXBxLNmZe7T3dScAnVJdku/5Zl5aFEpoNpRkT/VxNNiKySUTqRKReRO4Psz9FRJ509r8jIksm7HvAKa8TkZuma1NEKp02DjttJjvli0TkFRHZJSJ7ROQWN/uc6PY0dLFiYda8PJlzOssXZpISsEkCxsQC15KNiPiBR4GbgWrgThGpnlTtbqBDVZcBjwAPO8dWA1uA1cAm4Lsi4p+mzYeBR1R1OdDhtA3wNeApVb3cafO7bvTXhCYH7InA5IBxSX4fq0uz2WvJxpio5+aZzXqgXlWPquow8ASweVKdzcDjzvbTwEYREaf8CVUdUtVjQL3TXtg2nWNucNrAafPTzrYC42M6OUDjPPfTOE61D9A1MOLqzZyTrS3PZV9jF2M2ScCYqOZmsikDTk143+CUha2jqqNAF5B/gWOnKs8HOp02Jn/WN4DPi0gDsA3483DBisgXRGSHiOxoaWmZeS/NOQeaugFYXRq5ZFNdmk3/8Bgn2voi9pnGmNlzM9lImLLJf35OVWe+ygHuBP6XqpYDtwA/FpEP9VtVH1PVGlWtKSwsDNOcmU5tczcisGJhZsQ+c3wiwsGmnoh9pjFm9txMNg1AxYT35Xx4COtcHREJEBrmar/AsVOVtwK5ThuTP+tu4CkAVX0LSAUKLqJfZgq1TT0syc+Y18dAT2f5wkwCPuFAk123MSaauZlstgPLnVliyYQuzm+dVGcrcJezfQfwsoaW8d0KbHFmq1UCy4F3p2rTOeYVpw2cNp91tk8CGwFEZBWhZGPjZC6oO9PDyoVZEf3MlICfZUWZHGjsjujnGmNmx7Vk41w/uRd4CThIaEbYfhF5UERud6r9EMgXkXrgPuB+59j9hM5GDgAvAveo6thUbTptfQW4z2kr32kb4C+BPxOR3cBPgX+nti79vOsfHuV4Wx9VJZFNNhAaShu/XmSMiU6ujneo6jZCF+Unln19wvYg8Nkpjn0IeGgmbTrlRwnNVptcfgC4draxm9k5dKYXVagqdv9mzsmqS7N5Ztdp2nqHyM9MifjnG2OmZysImHlR65xZrPLozAZskoAx0cySjZkXtc09pCf7qchLj/hnr3KSjU0SMCZ6WbIx86K2uZsVC7Pw+cLNQndXXkYypTmpNknAmChmycZcNFWltrnHkyG0cdWlNknAmGhmycZctLM9Q3T2j3gyOWDcqpJsjrT0MTgy5lkMxpipWbIxF+2gc0axstjDM5uSbMaCyqEzNknAmGhkycZctNrm0C/4Ki+TTen4jDQbSjMmGlmyMRettqmbkpxUctOTPYuhIi+dzJSATRIwJkpZsjEXrba5x9MhNACfT6gqzrJ7bYyJUpZszEUZHg1ypKXX08kB41YWZ1Hb3I2tRmRM9LFkYy7K0dZeRsbU02nP46qKs+geHKW5e9DrUIwxk1iyMReltml8ckA0nNmEYhifsGCMiR6WbMxFqW3uIckvXFKY4XUo5x5vUGvXbYyJOpZszEWpbe5maWEmSX7vv5Vy0pMoyUmlrtlmpBkTbbz/DWFiWm1Tz7mFMKNBaJKAndkYE20s2Zg56+wfprl70NObOSdbWZzFkZZeRsaCXodijJnAko2Zs/EzCK/vsZmoqjiLkTHlWGuf16EYYyawZGPm7IMHpkXRMNpCm5FmTDSyZGPmrLa5h7z0JIqyoudRzEuLMvD7xCYJGBNlLNmYOatt7qGqOBuRyD8wbSopAT+XFGRQZ2c2xkQVSzZmToJBpS4K1kQLx2akGRN9LNmYOTnZ3s/AyFhULFMzWVVxFg0dA/QOjXodijHGYcnGzMkHz7CJnskB48aXrbGhNGOihyUbMye1zd2IwIqF0XlmA5ZsjIkmlmzMnNQ29bAkP4O0ZL/XoXxIWW4aGcl+m5FmTBSxZGPmpLa5O6pWDpjI5xNW2CQBY6KKJRsza/3Do5xo74/K6zXjqoqzqTvTYw9SMyZKWLIxs3boTC+q0bVMzWRVxVl09o9wtmfI61CMMViyMXPwwTI10ZtsxhOhDaUZEx0s2ZhZq23uIT3ZT0VeutehTOmDGWk2ScCYaOBqshGRTSJSJyL1InJ/mP0pIvKks/8dEVkyYd8DTnmdiNw0XZsiUum0cdhpM3nCvj8SkQMisl9EfuJejxNDbXM3K4uz8PmiZ5mayXLTk1mYnWJnNsZECdeSjYj4gUeBm4Fq4E4RqZ5U7W6gQ1WXAY8ADzvHVgNbgNXAJuC7IuKfps2HgUdUdTnQ4bSNiCwHHgCuVdXVwJdd6nJCUFVnTbToHUIbt7I42+61MSZKuHlmsx6oV9WjqjoMPAFsnlRnM/C4s/00sFFCqzpuBp5Q1SFVPQbUO+2FbdM55ganDZw2P+1s/xnwqKp2AKjqWRf6mjDOdA/R2T8S1TPRxlUVZ3H4bC+j9iA1YzznZrIpA05NeN/glIWto6qjQBeQf4FjpyrPBzqdNiZ/1gpghYi8ISJvi8imcMGKyBdEZIeI7GhpaZlVRxNJrXMNJCbObBZmMTwa5Hhbv9ehGJPw3Ew24Qb0J9/0MFWd+SoHCADLgQ3AncAPRCT3Q5VVH1PVGlWtKSwsDNOcgeheE22yD2ak2SQBY7w2o2QjIj8XkVtFZDbJqQGomPC+HGicqo6IBIAcoP0Cx05V3grkOm1M/qwG4FlVHXGG5OoIJR8zB7VN3ZTkpJKTnuR1KNNaVpTpPEjNrtsY47WZJo/vAX8MHBaRvxeRqhkcsx1Y7swSSyZ0wX/rpDpbgbuc7TuAlzV0y/dWYIszW62SUHJ4d6o2nWNecdrAafNZZ/sXwPUAIlJAaFjt6Az7bSaJlckBAKlJfioLMjjYZMnGGK/NKNmo6m9U9d8CVwDHgV+LyJsi8u9FJOyfuM71k3uBl4CDwFOqul9EHhSR251qPwTyRaQeuA+43zl2P/AUcAB4EbhHVcematNp6yvAfU5b+U7bOHXbROQAoYT0V6raNpN+m/MNjwY50tJLVUn0D6GNqyrOou6MDaMZ47XA9FVCRCQf+DzwJ8Au4F+A6widRWwId4yqbgO2TSr7+oTtQeCzUxz7EPDQTNp0yo8Smq02uVwJJbL7wnbMzNjR1l5GxjRmzmwAVpVk8/yeJnoGR8hKjf6hP2Pi1Uyv2TwD/A5IB25T1dtV9UlV/XMg080ATfSobYqdyQHjxhPjoTM2lGaMl2Z6ZvMD54ziHBFJce6DqXEhLhOFapt7SPILlxRmeB3KjE1cI+3KxQs8jsaYxDXTCQJ/G6bsrfkMxES/2uZulhVlkeSPnSX1ynLTyEoJnDsrM8Z444JnNiJSTOjmyDQRuZwP7mfJJjSkZhJIbVMP1yzN9zqMWRERqkqy7F4bYzw23TDaTcC/I3TfyrcnlPcAX3UpJhOFOvuHae4ejKnJAeNWFmfx7PuNqCqhlY2MMZF2wWSjqo8Dj4vIH6rqzyMUk4lC51YOiKFpz+OqirP534MnaewapCw3zetwjElI0w2jfV5V/zewREQ+NHVYVb8d5jATh849MC0Gz2zGH/JW29RtycYYj0x3pXd82lEmkBXmZRJEbXMPeelJFGaleB3KrK1YaE/tNMZr0w2jfd/5/3+LTDgmWh1s6mZVSXZMXvPISk2iPC/Nko0xHprpTZ3fFJFsEUkSkd+KSKuIfN7t4Ex0GAsqdWd6YupmzsmqirPPDQUaYyJvpjdMfFJVu4FPEVpFeQXwV65FZaLK8bY+BkeC5659xKKq4iyOtvYxNDrmdSjGJKSZJpvxRaVuAX6qqu0uxWOi0PgNkaticCbauKqSLMaCSv3ZXq9DMSYhzTTZPCcitUAN8FsRKQQG3QvLRJODTd34fcKyothdBm98CNBWEjDGGzN9xMD9wDVAjaqOAH3AZjcDM9HjYFM3SwszSE3yex3KnC3JTyc54KPOFuQ0xhMzfsQAsIrQ/TYTj/nRPMdjolBoEcs8r8O4KAG/jxULMzlokwSM8cSMko2I/BhYCrwPjF9hVSzZxL2u/hFOdw7w+Y8s9jqUi1ZVnM1rh1q8DsOYhDTTM5saoNp5EJlJIAedBSxjeSbauKriLJ7e2UBb7xD5mbF3c6oxsWymEwT2AcVuBmKi07llamJ4Jtq48UkCdXZzpzERN9MzmwLggIi8CwyNF6rq7a5EZaLGwaYeFmQkUxSDy9RMVuWcnR1s7uGjywo8jsaYxDLTZPMNN4Mw0etgczerSrJicpmayQoyUyjITKHOnm1jTMTNdOrza8BxIMnZ3g6852JcJgqMBZW65thepmayquIsDtq9NsZE3EzXRvsz4Gng+05RGfALt4Iy0eFYax9Do8G4uF4zrro0m7ozPYyMBb0OxZiEMtMJAvcA1wLdAKp6GChyKygTHQ42xc9MtHGrS7MZHg1ypMWWrTEmkmaabIZUdXj8jXNjp02DjnO1zd0EYnyZmslWl4bO0vaftus2xkTSTJPNayLyVSBNRD4B/Ax4zr2wTDQ42NTD0sJMUgKxu0zNZJUFmaQl+dnX2OV1KMYklJkmm/uBFmAv8J+AbcDX3ArKRIfapu64GkID8PuEqpIs9jfamY0xkTSjqc+qGhSRXwC/UFVb7yMBtPcN09g1GFeTA8atLs3m2V2NBIOKzxf7U7qNiQUXPLORkG+ISCtQC9SJSIuIfD0y4Rmv7HeGmS4ty/E4kvm3pjSHnqFRTnX0ex2KMQljumG0LxOahXaVquar6gLgauBaEfk/XY/OeGbv6VCyWV0af8lmvE/7bJKAMREzXbL5U+BOVT02XqCqR4HPO/tMnNp/uptFC9LJSU+avnKMWVGcScAn587ejDHumy7ZJKlq6+RC57rNtL+FRGSTiNSJSL2I3B9mf4qIPOnsf0dElkzY94BTXiciN03XpohUOm0cdtpMnvRZd4iIikjNdHGb0JnNmrL4u14DkBLws6wo0yYJGBNB0yWb4TnuQ0T8wKPAzUA1cKeIVE+qdjfQoarLgEeAh51jq4EtwGpgE/BdEfFP0+bDwCOquhzocNoejyUL+BLwzjT9NYSeYXOyvT8uh9DGrS7NYX9jF/bUDGMiY7pks05EusO8eoBLpzl2PVCvqkedG0Kf4MOPkt4MPO5sPw1slNCKj5uBJ1R1yBnCq3faC9umc8wNThs4bX56wuf8DfBNYHCamA2wvyl+JweMW1OWTWvvMGd7hqavbIy5aBdMNqrqV9XsMK8sVZ1uGK0MODXhfYNTFraOqo4CXUD+BY6dqjwf6HTaOO+zRORyoEJVn79QsCLyBRHZISI7WloSe3b3vnOTA+JzGA0+mCRg122MiYyZ3tQ5F+FuYJg8ZjFVnXkpFxEfoeG5v7xAnKHKqo+pao2q1hQWFk5XPa7tO91NaU5qXD/NcvxmVVu2xpjIcDPZNAAVE96XA41T1XHWW8sB2i9w7FTlrUCu08bE8ixgDfCqiBwHPgJstUkCF7avsYs1cTyEBpCVmsSS/HRbtsaYCHEz2WwHljuzxJIJXfDfOqnOVuAuZ/sO4GUNXbHdCmxxZqtVAsuBd6dq0znmFacNnDafVdUuVS1Q1SWqugR4G7hdVXe41elY1zs0yrHWvrhPNgCry3LsXhtjIsS1ZONcP7kXeAk4CDylqvtF5EERGX+c9A+BfBGpB+4jtAYbqrofeAo4ALwI3KOqY1O16bT1FeA+p618p20zSwcau1Elbqc9T7S2LIfTnQO09dokAWPcNtPHQs+Jqm4jtGjnxLKvT9geBD47xbEPAQ/NpE2n/Cih2WoXimfDTOJOZOOTAxLhzGZdRS4Aexq6uL7KHs9kjJvcHEYzMWjf6S6KslIoykr1OhTXrSnLQQR2N3R6HYoxcc+SjTnP7oZO1pbH/1kNQGZKgOVFmew+ZcnGGLdZsjHndA2McKSlj8uc4aVEsK48l90NtpKAMW6zZGPO2eMMJ61LpGRTkUt73zANHQNeh2JMXLNkY855/2Qo2awtT5xkM34WZ9dtjHGXJRtzzvunOllamEFOWvw9VmAqK4uzSA747LqNMS6zZGMAUFXeP9XJZRV5XocSUUl+H6tLs9l9ylYSMMZNlmwMAA0dA7T1DXPZosQZQhu3rjyXvae7GB0Leh2KMXHLko0BYJczjHR5Ak0OGHdZRS4DI2PUt/R6HYoxccuSjQFCkwNSAj5WFmd5HUrEjc++e++EXbcxxi2WbAwA75/q4NKyHJL8ifctsSQ/nfyMZHacaPc6FGPiVuL9ZjEfMjwaZF9jd0LdzDmRiHDl4jx2nujwOhRj4pYlG8OBpm6GR4NcviixZqJNdNWSBZxo6+dsjz053Bg3WLIxbD8WGj66akniJpsrnb7vPG5nN8a4wZKNYfvxdhbnp1OUHf8rPU9lTWkOKQEfO2wozRhXWLJJcKrKjhMd1Cxe4HUonkoO+FhXkWvJxhiXWLJJcEdaemnvG2Z9ZeIOoY2rWZzH/tNdDAyPeR2KMXHHkk2C2+5co7hqSWKf2QDULMljNBhatscYM78s2SS47cfaKchMprIgw+tQPHflolDC3XHc7rcxZr5Zsklw7x5vp2bxAkTE61A8l5OexIqFmWy36zbGzDtLNgmsqWuAho4Brqq0IbRxV1fms+N4OyO2KKcx88qSTQJ752houGi9Xa8559pl+fQPj517aqkxZn5Ysklgb9S3kpOWRHVpttehRI2rK/MRgTfq27wOxZi4YskmQakqb9S38tGl+fh9dr1mXF5GMtUl2bx5pNXrUIyJK5ZsEtTxtn4auwb56LICr0OJOh9dms97JzoZHLH7bYyZL5ZsEtTv60N/uV9nyeZDPrqsgOGxIDtsnTRj5o0lmwT1Zn0rZblpLMlP9zqUqHPVkgUEfGJDacbMI0s2CWgsqLx5pI2PLs23+2vCyEwJsK4ilzeO2CQBY+aLJZsEdKCxm66BEa5bbkNoU7luWQF7Gzrp6Bv2OhRj4oIlmwT0+uEWAK5Zmu9xJNHr+qoiggqvHWrxOhRj4oKryUZENolInYjUi8j9YfaniMiTzv53RGTJhH0POOV1InLTdG2KSKXTxmGnzWSn/D4ROSAie0TktyKy2M0+x4KXa89yaVkORVmJ+/ya6awty6EgM5mXa896HYoxccG1ZCMifuBR4GagGrhTRKonVbsb6FDVZcAjwMPOsdXAFmA1sAn4roj4p2nzYeARVV0OdDhtA+wCalR1LfA08E03+hsr2vuG2XWyg+urirwOJar5fMIfrCjitUMtjNrSNcZcNDfPbNYD9ap6VFWHgSeAzZPqbAYed7afBjZK6Ir1ZuAJVR1S1WNAvdNe2DadY25w2sBp89MAqvqKqvY75W8D5S70NWa8dugsQYWNlmymdX1VIV0DI/bIAWPmgZvJpgw4NeF9g1MWto6qjgJdQP4Fjp2qPB/odNqY6rMgdLbzQrhgReQLIrJDRHa0tMTvOP3LtS0UZKZwaVmO16FEvY8tL8TvExtKM2YeuJlsws2p1RnWma/yDz5I5PNADfCtMHVR1cdUtUZVawoLC8NViXmjY0FeqzvLhpWF+GyJmmnlpCVRszjPko0x88DNZNMAVEx4Xw40TlVHRAJADtB+gWOnKm8Fcp02PvRZInIj8NfA7ao6dFG9imHbj3fQPTjKDTaENmMbVxVR29zDqfb+6SsbY6bkZrLZDix3ZoklE7rgv3VSna3AXc72HcDLqqpO+RZntlolsBx4d6o2nWNecdrAafNZABG5HPg+oUST0H+ivrCviZSAjz9YEZ9nbm7YtLoEgBf3NXsciTGxzbVk41w/uRd4CTgIPKWq+0XkQRG53an2QyBfROqB+4D7nWP3A08BB4AXgXtUdWyqNp22vgLc57SV77QNoWGzTOBnIvK+iExOeAkhGFRe2NfM9SuLyEgJTH+AAWBRfjpryrLZtq/J61CMiWmu/tZR1W3AtkllX5+wPQh8dopjHwIemkmbTvlRQrPVJpffOOvA49COEx209Axx86XFXocSc25eU8K3XqqjsXOA0tw0r8MxJibZCgIJYtveJpIDPjauWuh1KDHnlktDQ2kv2FCaMXNmySYBBIPKi/ua2bCikEwbQpu1yoIMVpVks22vDaUZM1eWbBLA28faaO4e5Na1JV6HErNuW1fCzhMdnGjr8zoUY2KSJZsE8PTOBrJSAnyy2q7XzNVnLi9DBH7+3mmvQzEmJlmyiXO9Q6O8sLeZT60rIS3Z73U4MaskJ43rlhXwzHsNBIOT7002xkzHkk2ce2FvEwMjY9xxZUIvCTcv7riynIaOAd451u51KMbEHEs2ce7pnQ1UFmRwxaI8r0OJeZ+sLiYrJcDPdp6avrIx5jyWbOLYoTM9vHOsnTuuLLfHP8+DtGQ/my8v5fk9TbT1JuyqR8bMiSWbOPb4m8dJDvi4c/0ir0OJG3ddsz6KLwwAABEMSURBVITh0SBPbLezG2Nmw5JNnOrqH+GZ906zeV0pCzKSvQ4nbixfmMW1y/L5l7dP2EPVjJkFSzZx6mc7TzEwMsZdH13idShx50+vWUJj1yC/PnDG61CMiRmWbOLQ8GiQf/79MdYvWcAae0javLtx1UIWLUjne68dIbTguDFmOpZs4tDP32ugsWuQe25Y5nUoccnvE764YSl7Grp49VD8PtXVmPlkySbOjIwFefSVetZV5PLx5QVehxO3/s0V5ZTlpvGd3x62sxtjZsCSTZx55r0GGjoG+IuNy2y6s4uSAz7+84al7DrZyeuHW70Ox5ioZ8kmjvQNjfIPvzrEuopcrl9pj3522x/VlFOxII2/++VBm5lmzDQs2cSR7716hLM9Q3z9U9V2VhMBKQE/X715FXVnenhyh913Y8yFWLKJE6fa+3nsd0fZfFkpVy62pWkiZdOaYtZXLuAffnWIrv4Rr8MxJmpZsokDqspX/3UvAZ/wlU1VXoeTUESE/3pbNV0DIzz4/AGvwzEmatljG+PAT949ye8Ot/I3n15DaW6a1+EknNWlOdyzYSnfebmem9cUc2O1PXrbK31Do5zpHqStb5jh0SDDY0F8ImSmBMhKDbAwK5Wc9CSvw0xIlmxi3LHWPv7ulwe5blkBn7/a1kDzyr03LOdXB87wwL/uZW1FDkVZqV6HFNdUlSMtvbx7rIMDTV3UNfdQ19xD9+DotMdmpwZYlJ9OdUk2a8tzWVueQ3VJNgG/DfS4SewegQ+rqanRHTt2eB3GtHqHRvnMo2/Q2jvE81/6GGV2VuOp2uZuPvPom6wpy+Zf/uNHSA7YL6/51Dc0ym8OnuE3B8/y9tE2WnpCK29npQSoKsliZXEW5XnpLMxOIT8jhZSAj+SAj6AqPYOj9AyGznpOtvdzrLWPfae76HCus2WlBrh2aQEfX1HIhpWFNkIwRyKyU1Vrwu2zM5sYFQwq/9dTuznS0suP777aEk0UqCrO5uE71vKln+7iwef38zeb19iswIs0ODLGa4da2Lq7kd8ePMPgSJDCrBQ+ujSfay7J5yOX5LM4P31OX2dVpaFjgF2nOnmzvpXXD7Xw4v5mAC6ryOXWS0vYtKaYigXp892thGTJJgapKl97dh8v7m/ma7eu4tpltlJAtLh9XSn7G7v4/mtHWZCezH2fXOl1SDFndCzIm0fa2Lq7kZf2NdMzNEp+RjKfvbKC2y8r5cpFefh8F5/ERYSKBelULEjn9nWlztBcH7860My2vU08tO0gD207yLryHG5bV8qta0soybE/6ubKhtHCiOZhtGBQefD5A/yvN4/zxQ1L+S82+yzqqCr3/3wvT+44xV9+YgX33mCrOUwnGFR2nuxg6/uNbNvbRFvfMFkpAW5aU8xt60q5dml+xK+pnGzrZ9u+Jp7f08i+092IwFVLFnDbulJuWVNMfmZKROOJBRcaRrNkE0a0JpvBkTH+8qnd/HJvE3dfV8nXbl1lv8Si1FhQ+auf7eaZXaf546sX8eDtq+0C9CSqyv7GbrbubuT53Y00dg2SEvBx46qF3LaulA0rC0lN8nsdJgBHW3p5fk8TW3c3Un+2F79PuHZZAbetLeGmNcVkp9oMN7BkM2vRmGyOtvTy5SffZ09DF1+9pYo/+9gllmiiXDCofOtXdXzv1SOsr1zAI5+7LOGvrakqB5t62La3iV/ubeJYax8Bn/DxFYXcvq6UG6sXkpkSvaP7qkptcw/P7W5k6+5GGjoGSPb72LCykNsvK2Vj1ULSkqMjQXrBks0sRVOyGRkL8qO3TvD/vFRHSpKPb/7hWj65utjrsMwsPPNeA//3L/bh9wn337yKz11VgX8erjnEimBQOdDUzYv7QtdCjrb24RO4Zmk+n1pbys1rislNj72nyaoq75/qZOvuRn65p4mzPUOkJ/u5cdVCbl9XysdXFCbcjERLNrMUDclmdCzItn3NfOe3h6k/28sfrCjk4T9cS3GO3b8Ri0609fFXT+/h3WPtVJdk86WNy/lk9cJ5udAdjTr7h/nd4VZerWvhtUMttPYOnUswt1xawk2riymIo2seY0HlnWNtPLe7iRf2NdHZP0J2aoDrq4q4dlkB1y4rSIizWks2s+RlsjnR1sdzuxt5YvspGjoGuKQwg6/evIqNq4ps2CzGqSrP72niWy/VcbK9n0sKMvhsTQW3rSuhPC92p9eqKqfaB9hxop0dJzrYebyDQ2d7UIWctCQ+tryADSuL2LCyMK4SzFSGR4O8Ud/Kc7sbef1wC629wwBUFmTwkUsWsK48l7XluaxYmBl31/E8SzYisgn4fwE/8ANV/ftJ+1OAHwFXAm3A51T1uLPvAeBuYAz4kqq+dKE2RaQSeAJYALwH/ImqDl/oM6YSqWSjqrT2DrP7VCdvH23jraNt7G/sBmB95QL+43WV3Lgqfv/6TVSjY0Fe2NfM/3zjGO+d7ARgbXkO1ywN3TeyuiSbwqyUqPvjYng0SFPXAKfaBzjW2kttcw+1zT0cau6hZyh0535WSoDLF+dRsziPa5cVcFlFbkINGU6mqtSd6eGN+jbeqG9lx/H2c6scpCb5WF2aw/KiTJYWZrK0KINLCjIpzU2L2eE3T5KNiPiBQ8AngAZgO3Cnqh6YUOeLwFpV/c8isgX4jKp+TkSqgZ8C64FS4DfACuewsG2KyFPAM6r6hIj8E7BbVb831WdcKPaLSTaqysDIGH1DY/QNjdI7NEr/8Bgd/cOc7R7kbM8QZ7oHOd7Wz+EzPefuYE4O+Li8Ipcbqor41LrShDjlNqHptc/taeS1uhZ2nepgZCz085iXnsSKhVmU5aVRkpNKcU4ahZnJZKUmkZUacNb6SiI54CPJL/h9QpLPF/YPE1VlLKiMqaIaug44MDLG4HCQ/pFRBobHQq+RMXoGR2nrG6a9b4j2vmHa+4Zp6x3mdOcAzd2DTPx1kZUaoKo4dOf+qpJsrliUx4qFWQmdXKajqhxv62dPQyfvn+pk/+lujrT00tY3fF69gsxkinNSKc5Oozgnhdy0ZHLSkshJSyLb+X9WaoDUJB8pAT8pST5Sk/yhVRP8Ps/+UPEq2VwDfENVb3LePwCgqv99Qp2XnDpviUgAaAYKgfsn1h2v5xz2oTaBvwdagGJVHZ342VN9hl6g43NNNo+9foT//kItF/qS+n1CYWYKZXlprFiYyfKiLKpLs7msIjdqpnkab/QPj7L7VBe1zd3UNvVw+GwPzV2DnOkZYiw4s59TnxAamlEYUyXoJJjZ8vuEvPRkFmQksSAjmbLcdMrz0pxXOovz0ynJSY26s69Y1dE3zNHWXo6c7aOxa4Az3YM0dQ2G/v27B+kaGGGG3wKIQLLfh98n+EXw+QSfhP5NfRJ6+X2Cz0doWwRC/wHwFzeu4PZ1pXPqh1fL1ZQBE58o1QBcPVUdJ0l0AflO+duTji1ztsO1mQ90qupomPpTfcZ5z/IVkS8AXwBYtGhuC1peVpHHn1+/jPSUABnJfjJSAqQnB8hI8ZOTlkRxdir5mSn2l58JKz05wDVL87lmaf555WNBpbV3iNbeIXqdNb56h0bpGRpleDTI6FiQ0aAyMhZkdEwZCQYRBL8P/CKI88tl/JeN3wdpyQHSkvykJ/tJS/KTlhzazkgJkJ+RTHZqkg3fRlBeRjJXZizgysULwu4PBpXe4VG6+kfoGgi9+oZGGRwNMjQydu7/Q6NBBkfGGB4Nnnc2+8G2c5YbdM54nffn8phCbpo79wy5mWzCfadOzs1T1ZmqPNxA5oXqzzQOVPUx4DEIndmEOWZa6ysXsL4y/DeLMXPl9wkLs1NZmG0zEROVzydkpyaRnZpEhdfBzJGbV6Ea4LyvSznQOFUdZ4grB2i/wLFTlbcCuU4bkz9rqs8wxhgTIW4mm+3AchGpFJFkYAuwdVKdrcBdzvYdwMvOtZStwBYRSXFmmS0H3p2qTeeYV5w2cNp8dprPMMYYEyGuDaM510fuBV4iNE35n1V1v4g8COxQ1a3AD4Efi0g9obONLc6x+53ZZQeAUeAeVR0DCNem85FfAZ4Qkb8FdjltM9VnGGOMiRy7qTOMaFhBwBhjYs2FZqPF5p1DxhhjYoolG2OMMa6zZGOMMcZ1lmyMMca4ziYIhCEiLcAJr+NwFDBptYM4E+/9g/jvo/Uv9s1XHxeramG4HZZsopyI7Jhqdkc8iPf+Qfz30foX+yLRRxtGM8YY4zpLNsYYY1xnySb6PeZ1AC6L9/5B/PfR+hf7XO+jXbMxxhjjOjuzMcYY4zpLNsYYY1xnySbCROSzIrJfRIIiUjNp3wMiUi8idSJy04TyTU5ZvYjcP6G8UkTeEZHDIvKk89gFnEczPOnUf0dElkSqf7MxVb+ikYj8s4icFZF9E8oWiMivna//r0UkzykXEfmO0689InLFhGPucuofFpG7JpRfKSJ7nWO+IxF+3rKIVIjIKyJy0Pn+/It46qOIpIrIuyKy2+nff3PKZ/0zNNuf00gSEb+I7BKR55330dM/dR4Vaq/IvIBVwErgVaBmQnk1sBtIASqBI4Qeo+B3ti8Bkp061c4xTwFbnO1/Av4PZ/uLwD8521uAJ73ud5ivw5T9isYX8HHgCmDfhLJvAvc72/cDDzvbtwAvEHpK7EeAd5zyBcBR5/95znaes+9d4BrnmBeAmyPcvxLgCmc7CzjkfE/GRR+dz8x0tpOAd5y4Z/UzNJef0wj/O94H/AR43nkfNf2zM5sIU9WDqloXZtdm4AlVHVLVY0A9sN551avqUVUdBp4ANjt/Fd4APO0c/zjw6QltPe5sPw1sjPRfyjMQtl8exzQlVX2dDz/hdeLXefLX/0ca8jahp8iWADcBv1bVdlXtAH4NbHL2ZavqWxr6if/RhLYiQlWbVPU9Z7sHOAiUESd9dOLsdd4mOS9l9j9Ds/o5dblb5xGRcuBW4AfO+7n8jnCtf5ZsokcZcGrC+wanbKryfKBTVUcnlZ/XlrO/y6kfTabqVyxZqKpNEPplDRQ55bP9tyxztieXe8IZUrmc0F//cdNHZ4jpfeAsoSR4hNn/DM2235H0j8B/AYLO+7n8jnCtf5ZsXCAivxGRfWFeF/pLINyZh86h/EJtRZNYiHGu5vPfMqJEJBP4OfBlVe2+UNUwZVHdR1UdU9XLgHJCf6mvukBMMdU/EfkUcFZVd04sDlPVs/659ljoRKaqN87hsAagYsL7cqDR2Q5X3kpo6CLg/GUysf54Ww0iEgBy+PAQkNcu1N9YcUZESlS1yRkmOuuUT9W3BmDDpPJXnfLyMPUjSkSSCCWaf1HVZ5ziuOojgKp2isirhK7ZzPZnaLY/p5FyLXC7iNwCpALZhM50oqd/kb6AZa9zF/Je5fwJAqs5/8LcUUIX5QLOdiUfXJhb7RzzM86/+PdFZ/sezr/495TX/Q3T/yn7Fa0vYAnnTxD4FudfPP+ms30r5188f9cpXwAcI3ThPM/ZXuDs2+7UHb94fkuE+yaErqP846TyuOgjUAjkOttpwO+AT832Z2guP6cefJ9u4IMJAlHTP89/gBPtBXyG0F8PQ8AZ4KUJ+/6a0DhyHRNm6hCa+XPI2ffXE8ovITTDp975pkpxylOd9/XO/ku87vcUX4uw/YrGF/BToAkYcf797iY0xv1b4LDz//FfqgI86vRrL+f/UfEfnH+XeuDfTyivAfY5x/x/OKt7RLB/1xEaFtkDvO+8bomXPgJrgV1O//YBX3fKZ/0zNNufUw++VzfwQbKJmv7ZcjXGGGNcZxMEjDHGuM6SjTHGGNdZsjHGGOM6SzbGGGNcZ8nGGGOM6yzZGGOMcZ0lG2OMMa77/wEVyf+df7rHTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts_app_type.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T13', 'T12', 'T2', 'T25', 'T14', 'T29', 'T15', 'T17']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "replace_app_typ = list(counts_app_type[counts_app_type <100].index)\n",
    "replace_app_typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replace_app_typ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from t9 and up there are 9 major types of applications so I will set other for those \n",
    "# for alg in replace_alg:\n",
    "#     df_crypto.Algorithm = df_crypto.Algorithm.replace(alg,\"Other\")\n",
    "\n",
    "for typ in replace_app_typ:\n",
    "    charity_df.APPLICATION_TYPE = charity_df.APPLICATION_TYPE.replace(typ,\"T_Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3         27037\n",
       "T4          1542\n",
       "T6          1216\n",
       "T5          1173\n",
       "T19         1065\n",
       "T8           737\n",
       "T7           725\n",
       "T10          528\n",
       "T9           156\n",
       "T_Other      120\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_app_type = charity_df['APPLICATION_TYPE'].value_counts()\n",
    "counts_app_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete binning of application type \n",
    "# start binning of classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10520599</th>\n",
       "      <td>T_Other</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10531628</th>\n",
       "      <td>T_Other</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10547893</th>\n",
       "      <td>T_Other</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10553066</th>\n",
       "      <td>T_Other</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10556103</th>\n",
       "      <td>T_Other</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "10520599          T_Other       Independent          C1000    ProductDev   \n",
       "10531628          T_Other       Independent          C2000  Preservation   \n",
       "10547893          T_Other  CompanySponsored          C3000    ProductDev   \n",
       "10553066          T_Other  CompanySponsored          C2000  Preservation   \n",
       "10556103          T_Other       Independent          C1000     Heathcare   \n",
       "\n",
       "          ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "10520599   Association       1              0                      N     5000   \n",
       "10531628  Co-operative       1         1-9999                      N   108590   \n",
       "10547893   Association       1              0                      N     5000   \n",
       "10553066         Trust       1    10000-24999                      N     6692   \n",
       "10556103         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "          IS_SUCCESSFUL  \n",
       "10520599              1  \n",
       "10531628              1  \n",
       "10547893              0  \n",
       "10553066              1  \n",
       "10556103              1  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C2300       32\n",
       "C7200       32\n",
       "C1240       30\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_classif_type = charity_df['CLASSIFICATION'].value_counts()\n",
    "counts_classif_type.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C5000',\n",
       " 'C1270',\n",
       " 'C2700',\n",
       " 'C2800',\n",
       " 'C7100',\n",
       " 'C1300',\n",
       " 'C1280',\n",
       " 'C1230',\n",
       " 'C1400',\n",
       " 'C2300',\n",
       " 'C7200',\n",
       " 'C1240',\n",
       " 'C8000',\n",
       " 'C7120',\n",
       " 'C1500',\n",
       " 'C6000',\n",
       " 'C1800',\n",
       " 'C1250',\n",
       " 'C8200',\n",
       " 'C1238',\n",
       " 'C1278',\n",
       " 'C1237',\n",
       " 'C1235',\n",
       " 'C7210',\n",
       " 'C2400',\n",
       " 'C1720',\n",
       " 'C4100',\n",
       " 'C1257',\n",
       " 'C1600',\n",
       " 'C0',\n",
       " 'C2710',\n",
       " 'C1260',\n",
       " 'C1246',\n",
       " 'C1256',\n",
       " 'C1234',\n",
       " 'C1267',\n",
       " 'C3200',\n",
       " 'C1248',\n",
       " 'C2380',\n",
       " 'C1900',\n",
       " 'C3700',\n",
       " 'C1580',\n",
       " 'C2570',\n",
       " 'C1728',\n",
       " 'C1570',\n",
       " 'C2170',\n",
       " 'C6100',\n",
       " 'C2150',\n",
       " 'C5200',\n",
       " 'C1236',\n",
       " 'C1245',\n",
       " 'C4120',\n",
       " 'C2600',\n",
       " 'C1732',\n",
       " 'C1820',\n",
       " 'C2190',\n",
       " 'C8210',\n",
       " 'C4500',\n",
       " 'C1370',\n",
       " 'C1283',\n",
       " 'C2561',\n",
       " 'C4200',\n",
       " 'C2500']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_classif_typ = list(counts_classif_type[counts_classif_type <180].index)\n",
    "replace_classif_typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replace_classif_typ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for typ in replace_app_typ:\n",
    "#     charity_df.APPLICATION_TYPE = charity_df.APPLICATION_TYPE.replace(typ,\"T_Other\")\n",
    "    \n",
    "for cls in replace_classif_typ:\n",
    "    charity_df.CLASSIFICATION = charity_df.CLASSIFICATION.replace(cls,\"C_Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000      17326\n",
       "C2000       6074\n",
       "C1200       4837\n",
       "C3000       1918\n",
       "C2100       1883\n",
       "C_Other     1003\n",
       "C7000        777\n",
       "C1700        287\n",
       "C4000        194\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_classif_type = charity_df['CLASSIFICATION'].value_counts()\n",
    "counts_classif_type.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# completed binning of coloumns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable list\n",
    "charity_cat = charity_df.dtypes[charity_df.dtypes == \"object\"].index.tolist()\n",
    "charity_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE          10\n",
       "AFFILIATION                6\n",
       "CLASSIFICATION             9\n",
       "USE_CASE                   5\n",
       "ORGANIZATION               4\n",
       "INCOME_AMT                 9\n",
       "SPECIAL_CONSIDERATIONS     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attrition_df[attrition_cat].nunique()\n",
    "#check # of unq val in each column \n",
    "charity_df[charity_cat].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "      <th>APPLICATION_TYPE_T9</th>\n",
       "      <th>APPLICATION_TYPE_T_Other</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                   1.0                   0.0                  0.0   \n",
       "1                   0.0                   0.0                  1.0   \n",
       "2                   0.0                   0.0                  0.0   \n",
       "3                   0.0                   0.0                  1.0   \n",
       "4                   0.0                   0.0                  1.0   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  1.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  APPLICATION_TYPE_T9  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T_Other  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0                       0.0  ...                0.0                     0.0   \n",
       "1                       0.0  ...                1.0                     0.0   \n",
       "2                       0.0  ...                0.0                     0.0   \n",
       "3                       0.0  ...                0.0                     1.0   \n",
       "4                       0.0  ...                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                     0.0              0.0                0.0   \n",
       "1                     0.0              0.0                0.0   \n",
       "2                     0.0              0.0                0.0   \n",
       "3                     0.0              0.0                0.0   \n",
       "4                     0.0              0.0                0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       1.0                       0.0  \n",
       "1                       1.0                       0.0  \n",
       "2                       1.0                       0.0  \n",
       "3                       1.0                       0.0  \n",
       "4                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(charity_df[charity_cat]))\n",
    "\n",
    "# Add the encoded variable names to the DataFrame\n",
    "encode_df.columns = enc.get_feature_names(charity_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34299"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encode_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  ...  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0              1  ...                0.0                     0.0   \n",
       "1              1  ...                1.0                     0.0   \n",
       "2              0  ...                0.0                     0.0   \n",
       "3              1  ...                0.0                     1.0   \n",
       "4              1  ...                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
       "0                       0.0                 0.0               0.0   \n",
       "1                       0.0                 0.0               0.0   \n",
       "2                       0.0                 0.0               0.0   \n",
       "3                       0.0                 0.0               0.0   \n",
       "4                       1.0                 0.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \\\n",
       "0                     0.0              0.0                0.0   \n",
       "1                     0.0              0.0                0.0   \n",
       "2                     0.0              0.0                0.0   \n",
       "3                     0.0              0.0                0.0   \n",
       "4                     0.0              0.0                0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       1.0                       0.0  \n",
       "1                       1.0                       0.0  \n",
       "2                       1.0                       0.0  \n",
       "3                       1.0                       0.0  \n",
       "4                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Merge one-hot encoded features and drop the originals\n",
    "# attrition_df = attrition_df.merge(encode_df,left_index=True, right_index=True)\n",
    "# attrition_df = attrition_df.drop(attrition_cat,1)\n",
    "# attrition_df.head()\n",
    "\n",
    "# Merge one-hot encoded features and drop the originals\n",
    "charity_df = charity_df.merge(encode_df,left_index=True, right_index=True)\n",
    "charity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  \\\n",
       "0       1     5000              1                   1.0                   0.0   \n",
       "1       1   108590              1                   0.0                   0.0   \n",
       "2       1     5000              0                   0.0                   0.0   \n",
       "3       1     6692              1                   0.0                   0.0   \n",
       "4       1   142590              1                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  1.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  1.0   \n",
       "3                  1.0                  0.0                  0.0   \n",
       "4                  1.0                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  INCOME_AMT_1-9999  \\\n",
       "0                  0.0                  0.0  ...                0.0   \n",
       "1                  0.0                  0.0  ...                1.0   \n",
       "2                  0.0                  0.0  ...                0.0   \n",
       "3                  0.0                  0.0  ...                0.0   \n",
       "4                  0.0                  0.0  ...                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                0.0                       1.0                       0.0  \n",
       "1                0.0                       1.0                       0.0  \n",
       "2                0.0                       1.0                       0.0  \n",
       "3                0.0                       1.0                       0.0  \n",
       "4                0.0                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charity_df = charity_df.drop(charity_cat,1)\n",
    "charity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# # Split our preprocessed data into our features and target arrays\n",
    "# y = attrition_df[\"Attrition_Yes\"].values\n",
    "# X = attrition_df.drop([\"Attrition_Yes\",\"Attrition_No\"],1).values\n",
    "\n",
    "y = charity_df[\"IS_SUCCESSFUL\"].values\n",
    "X = charity_df.drop([\"IS_SUCCESSFUL\"],1).values\n",
    "\n",
    "# # Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e+00, 5.e+03, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 1.e+00,\n",
       "       0.e+00, 0.e+00, 0.e+00, 0.e+00, 1.e+00, 0.e+00, 0.e+00, 0.e+00,\n",
       "       0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 1.e+00, 0.e+00, 0.e+00,\n",
       "       0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 1.e+00,\n",
       "       0.e+00, 0.e+00, 0.e+00, 1.e+00, 1.e+00, 0.e+00, 0.e+00, 0.e+00,\n",
       "       0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 1.e+00, 0.e+00])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inital attempt with 1 layer of 8 nodes 48 inputs which created 393 params (probably to many ? )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 384       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 393\n",
      "Trainable params: 393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# # Second hidden layer\n",
    "# nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 6s 249us/sample - loss: 0.6039 - accuracy: 0.7026\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 5s 175us/sample - loss: 0.5650 - accuracy: 0.7264\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 5s 180us/sample - loss: 0.5610 - accuracy: 0.7285\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 5s 186us/sample - loss: 0.5590 - accuracy: 0.7294\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 5s 197us/sample - loss: 0.5574 - accuracy: 0.7295\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 5s 195us/sample - loss: 0.5560 - accuracy: 0.7306\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 6s 217us/sample - loss: 0.5551 - accuracy: 0.7301\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - ETA: 0s - loss: 0.5540 - accuracy: 0.73 - 5s 209us/sample - loss: 0.5541 - accuracy: 0.7307\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 5s 211us/sample - loss: 0.5536 - accuracy: 0.7303\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 5s 194us/sample - loss: 0.5533 - accuracy: 0.7322\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 5s 205us/sample - loss: 0.5524 - accuracy: 0.7308\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 5s 204us/sample - loss: 0.5527 - accuracy: 0.7311\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 5s 199us/sample - loss: 0.5522 - accuracy: 0.7303\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 5s 196us/sample - loss: 0.5521 - accuracy: 0.7310\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 5s 194us/sample - loss: 0.5516 - accuracy: 0.7308\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 5s 178us/sample - loss: 0.5515 - accuracy: 0.7308\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 5s 191us/sample - loss: 0.5513 - accuracy: 0.7309\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 5s 195us/sample - loss: 0.5509 - accuracy: 0.7301\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 5s 208us/sample - loss: 0.5508 - accuracy: 0.7308\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 5s 203us/sample - loss: 0.5506 - accuracy: 0.7309\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 5s 195us/sample - loss: 0.5507 - accuracy: 0.7313\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 5s 191us/sample - loss: 0.5505 - accuracy: 0.7315\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 5s 197us/sample - loss: 0.5504 - accuracy: 0.7311\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 5s 178us/sample - loss: 0.5504 - accuracy: 0.7307\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 5s 184us/sample - loss: 0.5499 - accuracy: 0.7311\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 5s 186us/sample - loss: 0.5498 - accuracy: 0.7313\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 5s 200us/sample - loss: 0.5497 - accuracy: 0.7308\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 5s 196us/sample - loss: 0.5495 - accuracy: 0.7313\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 5s 199us/sample - loss: 0.5496 - accuracy: 0.7320\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 5s 186us/sample - loss: 0.5493 - accuracy: 0.7313 - los\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 5s 184us/sample - loss: 0.5491 - accuracy: 0.7310\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 5s 183us/sample - loss: 0.5490 - accuracy: 0.7314\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 5s 182us/sample - loss: 0.5487 - accuracy: 0.7314\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 5s 202us/sample - loss: 0.5486 - accuracy: 0.7329\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 5s 187us/sample - loss: 0.5489 - accuracy: 0.7316\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 5s 198us/sample - loss: 0.5485 - accuracy: 0.7310\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 5s 194us/sample - loss: 0.5483 - accuracy: 0.7325\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 4s 152us/sample - loss: 0.5482 - accuracy: 0.7324\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 4s 170us/sample - loss: 0.5483 - accuracy: 0.7306\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 5s 208us/sample - loss: 0.5480 - accuracy: 0.7324\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 5s 197us/sample - loss: 0.5481 - accuracy: 0.7313\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 5s 202us/sample - loss: 0.5481 - accuracy: 0.7317\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 5s 195us/sample - loss: 0.5479 - accuracy: 0.7316\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 5s 193us/sample - loss: 0.5479 - accuracy: 0.7323\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 5s 189us/sample - loss: 0.5478 - accuracy: 0.7323\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 5s 198us/sample - loss: 0.5480 - accuracy: 0.7313\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 5s 188us/sample - loss: 0.5475 - accuracy: 0.7326\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 5s 206us/sample - loss: 0.5477 - accuracy: 0.7333\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 5s 198us/sample - loss: 0.5475 - accuracy: 0.7329\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 5s 194us/sample - loss: 0.5472 - accuracy: 0.7329\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 5s 201us/sample - loss: 0.5471 - accuracy: 0.7330\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 5s 202us/sample - loss: 0.5471 - accuracy: 0.7322\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 5s 198us/sample - loss: 0.5472 - accuracy: 0.7329\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 5s 204us/sample - loss: 0.5467 - accuracy: 0.7324\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 5s 195us/sample - loss: 0.5472 - accuracy: 0.7326\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 5s 186us/sample - loss: 0.5471 - accuracy: 0.7324\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 5s 187us/sample - loss: 0.5469 - accuracy: 0.7330\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 5s 187us/sample - loss: 0.5468 - accuracy: 0.7325\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 5s 196us/sample - loss: 0.5468 - accuracy: 0.7343\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 5s 195us/sample - loss: 0.5466 - accuracy: 0.7331\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 5s 192us/sample - loss: 0.5466 - accuracy: 0.7331\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 5s 192us/sample - loss: 0.5467 - accuracy: 0.7330\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 5s 207us/sample - loss: 0.5467 - accuracy: 0.7335\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 4s 157us/sample - loss: 0.5466 - accuracy: 0.7331\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 4s 148us/sample - loss: 0.5466 - accuracy: 0.7331\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 4s 146us/sample - loss: 0.5465 - accuracy: 0.7329\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 5s 211us/sample - loss: 0.5464 - accuracy: 0.7335\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 4s 170us/sample - loss: 0.5463 - accuracy: 0.7334\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 4s 147us/sample - loss: 0.5465 - accuracy: 0.7337\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 4s 149us/sample - loss: 0.5461 - accuracy: 0.7333\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 5s 202us/sample - loss: 0.5461 - accuracy: 0.7339\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 6s 249us/sample - loss: 0.5463 - accuracy: 0.7339\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 6s 247us/sample - loss: 0.5462 - accuracy: 0.7329\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 6s 240us/sample - loss: 0.5462 - accuracy: 0.7336 - loss: 0\n",
      "Epoch 75/100\n",
      "25724/25724 [==============================] - 7s 253us/sample - loss: 0.5460 - accuracy: 0.7340\n",
      "Epoch 76/100\n",
      "25724/25724 [==============================] - 6s 250us/sample - loss: 0.5461 - accuracy: 0.7336\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 7s 264us/sample - loss: 0.5460 - accuracy: 0.7338\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 7s 261us/sample - loss: 0.5458 - accuracy: 0.7339\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 7s 280us/sample - loss: 0.5456 - accuracy: 0.7339\n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 7s 280us/sample - loss: 0.5457 - accuracy: 0.7336\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 7s 257us/sample - loss: 0.5461 - accuracy: 0.7333\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 7s 266us/sample - loss: 0.5455 - accuracy: 0.7336\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 6s 232us/sample - loss: 0.5459 - accuracy: 0.7335\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 7s 254us/sample - loss: 0.5457 - accuracy: 0.7332\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 7s 259us/sample - loss: 0.5457 - accuracy: 0.7345\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 7s 264us/sample - loss: 0.5457 - accuracy: 0.7327\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 7s 262us/sample - loss: 0.5458 - accuracy: 0.7341\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 7s 260us/sample - loss: 0.5457 - accuracy: 0.7336\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 7s 265us/sample - loss: 0.5457 - accuracy: 0.7332\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 6s 246us/sample - loss: 0.5455 - accuracy: 0.7344\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 6s 232us/sample - loss: 0.5456 - accuracy: 0.7343\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 7s 267us/sample - loss: 0.5456 - accuracy: 0.7336\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 7s 270us/sample - loss: 0.5455 - accuracy: 0.7341\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 7s 261us/sample - loss: 0.5457 - accuracy: 0.7338\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - ETA: 0s - loss: 0.5453 - accuracy: 0.73 - 7s 258us/sample - loss: 0.5455 - accuracy: 0.7337\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 7s 272us/sample - loss: 0.5453 - accuracy: 0.7345\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 7s 269us/sample - loss: 0.5452 - accuracy: 0.7345\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 7s 267us/sample - loss: 0.5453 - accuracy: 0.7336\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 7s 266us/sample - loss: 0.5452 - accuracy: 0.7348\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 7s 271us/sample - loss: 0.5453 - accuracy: 0.7344\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 2s - loss: 129900.1759 - accuracy: 0.5332\n",
      "Loss: 218701.59398391945, Accuracy: 0.5331778526306152\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial loss 218701 so thats not good. accuracy is just above 50 % so pretty bad also "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initial run taking 2 seconds per epoch and loss is going down super slowly , probably cut down on \n",
    "# the number of inputs and the number of neurons \n",
    "# maybe what would optimal number of imputs be, do I need one for each row ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6)                 288       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 313\n",
      "Trainable params: 313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  6\n",
    "hidden_nodes_layer2 = 3\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 11s 426us/sample - loss: 0.6408 - accuracy: 0.6474\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 7s 256us/sample - loss: 0.5793 - accuracy: 0.7252\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 7s 281us/sample - loss: 0.5657 - accuracy: 0.7260\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 7s 279us/sample - loss: 0.5618 - accuracy: 0.7280\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 7s 286us/sample - loss: 0.5596 - accuracy: 0.7269\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 7s 285us/sample - loss: 0.5581 - accuracy: 0.7279\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 7s 286us/sample - loss: 0.5573 - accuracy: 0.7285\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 7s 290us/sample - loss: 0.5564 - accuracy: 0.7289\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 8s 294us/sample - loss: 0.5560 - accuracy: 0.7290\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 7s 260us/sample - loss: 0.5554 - accuracy: 0.7285\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 7s 253us/sample - loss: 0.5551 - accuracy: 0.7284\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 7s 287us/sample - loss: 0.5546 - accuracy: 0.7297\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 8s 293us/sample - loss: 0.5542 - accuracy: 0.7287\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 7s 284us/sample - loss: 0.5537 - accuracy: 0.7290\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 8s 296us/sample - loss: 0.5538 - accuracy: 0.7294\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 7s 285us/sample - loss: 0.5532 - accuracy: 0.7288\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 7s 290us/sample - loss: 0.5530 - accuracy: 0.7285\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 8s 295us/sample - loss: 0.5530 - accuracy: 0.7292\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 8s 296us/sample - loss: 0.5529 - accuracy: 0.7294\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 7s 287us/sample - loss: 0.5524 - accuracy: 0.7290\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 7s 287us/sample - loss: 0.5523 - accuracy: 0.7294\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 7s 287us/sample - loss: 0.5522 - accuracy: 0.7294\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 8s 292us/sample - loss: 0.5519 - accuracy: 0.7288\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 8s 301us/sample - loss: 0.5517 - accuracy: 0.7296\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 8s 293us/sample - loss: 0.5518 - accuracy: 0.7296\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 7s 279us/sample - loss: 0.5515 - accuracy: 0.7296\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 7s 287us/sample - loss: 0.5515 - accuracy: 0.7288\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 7s 289us/sample - loss: 0.5513 - accuracy: 0.7292\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 7s 283us/sample - loss: 0.5513 - accuracy: 0.7302\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 7s 290us/sample - loss: 0.5512 - accuracy: 0.7297\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 7s 281us/sample - loss: 0.5512 - accuracy: 0.7297\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 7s 281us/sample - loss: 0.5511 - accuracy: 0.7301\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 7s 283us/sample - loss: 0.5510 - accuracy: 0.7304\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 7s 275us/sample - loss: 0.5510 - accuracy: 0.7304\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 7s 272us/sample - loss: 0.5506 - accuracy: 0.7310\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 7s 286us/sample - loss: 0.5508 - accuracy: 0.7308\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 7s 263us/sample - loss: 0.5505 - accuracy: 0.7310\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 7s 272us/sample - loss: 0.5505 - accuracy: 0.7301\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 7s 267us/sample - loss: 0.5504 - accuracy: 0.7306\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 7s 276us/sample - loss: 0.5505 - accuracy: 0.7311\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 7s 273us/sample - loss: 0.5501 - accuracy: 0.7312\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 7s 271us/sample - loss: 0.5505 - accuracy: 0.7312\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 7s 258us/sample - loss: 0.5503 - accuracy: 0.7314\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 7s 272us/sample - loss: 0.5500 - accuracy: 0.7316\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 7s 265us/sample - loss: 0.5498 - accuracy: 0.7309\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 7s 266us/sample - loss: 0.5499 - accuracy: 0.7310\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 7s 270us/sample - loss: 0.5498 - accuracy: 0.7322\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 7s 265us/sample - loss: 0.5497 - accuracy: 0.7317\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 7s 262us/sample - loss: 0.5495 - accuracy: 0.7322\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 7s 266us/sample - loss: 0.5497 - accuracy: 0.7319\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 7s 265us/sample - loss: 0.5498 - accuracy: 0.7321\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 7s 268us/sample - loss: 0.5492 - accuracy: 0.7314\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 7s 261us/sample - loss: 0.5494 - accuracy: 0.7317\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 7s 269us/sample - loss: 0.5492 - accuracy: 0.7312\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 7s 271us/sample - loss: 0.5496 - accuracy: 0.7316\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 7s 264us/sample - loss: 0.5491 - accuracy: 0.7319\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 7s 262us/sample - loss: 0.5493 - accuracy: 0.7320\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 7s 274us/sample - loss: 0.5490 - accuracy: 0.7326\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 7s 266us/sample - loss: 0.5496 - accuracy: 0.7317\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 7s 258us/sample - loss: 0.5492 - accuracy: 0.7315\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 7s 266us/sample - loss: 0.5491 - accuracy: 0.7319\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 7s 272us/sample - loss: 0.5492 - accuracy: 0.7320\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 7s 271us/sample - loss: 0.5492 - accuracy: 0.7325\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 7s 263us/sample - loss: 0.5489 - accuracy: 0.7321\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 7s 271us/sample - loss: 0.5490 - accuracy: 0.7323\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 7s 270us/sample - loss: 0.5488 - accuracy: 0.7322\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 7s 269us/sample - loss: 0.5491 - accuracy: 0.7318\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 7s 267us/sample - loss: 0.5487 - accuracy: 0.7321\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 7s 256us/sample - loss: 0.5487 - accuracy: 0.7327 - loss: 0.547\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 7s 265us/sample - loss: 0.5489 - accuracy: 0.7325\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 7s 270us/sample - loss: 0.5487 - accuracy: 0.7320\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 7s 267us/sample - loss: 0.5488 - accuracy: 0.7322\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 7s 271us/sample - loss: 0.5485 - accuracy: 0.7322\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 7s 282us/sample - loss: 0.5487 - accuracy: 0.7324\n",
      "Epoch 75/100\n",
      "25724/25724 [==============================] - 8s 301us/sample - loss: 0.5484 - accuracy: 0.7326\n",
      "Epoch 76/100\n",
      "25724/25724 [==============================] - 8s 304us/sample - loss: 0.5487 - accuracy: 0.7322\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 8s 298us/sample - loss: 0.5484 - accuracy: 0.7319\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 8s 299us/sample - loss: 0.5486 - accuracy: 0.7324\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 8s 299us/sample - loss: 0.5484 - accuracy: 0.7324\n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 8s 294us/sample - loss: 0.5483 - accuracy: 0.7324\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 8s 301us/sample - loss: 0.5485 - accuracy: 0.7323\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 8s 308us/sample - loss: 0.5482 - accuracy: 0.7325\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 8s 297us/sample - loss: 0.5487 - accuracy: 0.7324\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 8s 296us/sample - loss: 0.5481 - accuracy: 0.7327\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 8s 297us/sample - loss: 0.5483 - accuracy: 0.7325\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 8s 301us/sample - loss: 0.5481 - accuracy: 0.7329\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 8s 292us/sample - loss: 0.5483 - accuracy: 0.7323\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 8s 305us/sample - loss: 0.5480 - accuracy: 0.7326\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 7s 291us/sample - loss: 0.5481 - accuracy: 0.7328\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 7s 291us/sample - loss: 0.5483 - accuracy: 0.7318\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 7s 289us/sample - loss: 0.5481 - accuracy: 0.7322\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 7s 290us/sample - loss: 0.5482 - accuracy: 0.7324\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 7s 282us/sample - loss: 0.5481 - accuracy: 0.7332 - loss: 0.5473 - accuracy: 0.\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 7s 290us/sample - loss: 0.5479 - accuracy: 0.7322\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - 8s 293us/sample - loss: 0.5482 - accuracy: 0.7324\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 8s 303us/sample - loss: 0.5485 - accuracy: 0.7324\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 7s 280us/sample - loss: 0.5478 - accuracy: 0.7326\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 8s 297us/sample - loss: 0.5479 - accuracy: 0.7324\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 8s 301us/sample - loss: 0.5480 - accuracy: 0.7324\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 8s 299us/sample - loss: 0.5480 - accuracy: 0.7324\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 2s - loss: 0.7158 - accuracy: 0.4668\n",
      "Loss: 0.7135379090601084, Accuracy: 0.46682214736938477\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy went down but loss went down by a lot so going to try it again with 50 insead of a hundred epocs to see if half will cause less over fitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 7s 281us/sample - loss: 0.5479 - accuracy: 0.7320\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 7s 270us/sample - loss: 0.5479 - accuracy: 0.7325\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 7s 265us/sample - loss: 0.5478 - accuracy: 0.7322\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 7s 264us/sample - loss: 0.5477 - accuracy: 0.7327\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 7s 260us/sample - loss: 0.5477 - accuracy: 0.7322\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 7s 280us/sample - loss: 0.5477 - accuracy: 0.7329\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 7s 283us/sample - loss: 0.5478 - accuracy: 0.7321\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 7s 270us/sample - loss: 0.5474 - accuracy: 0.7320\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 7s 275us/sample - loss: 0.5476 - accuracy: 0.7334\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 7s 268us/sample - loss: 0.5474 - accuracy: 0.7319\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 7s 274us/sample - loss: 0.5474 - accuracy: 0.7326\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 7s 267us/sample - loss: 0.5473 - accuracy: 0.7318\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 7s 269us/sample - loss: 0.5476 - accuracy: 0.7334\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 7s 270us/sample - loss: 0.5473 - accuracy: 0.7323\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 7s 259us/sample - loss: 0.5471 - accuracy: 0.7329\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 7s 265us/sample - loss: 0.5471 - accuracy: 0.7321\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 7s 276us/sample - loss: 0.5475 - accuracy: 0.7322\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 7s 255us/sample - loss: 0.5470 - accuracy: 0.7331\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 7s 282us/sample - loss: 0.5471 - accuracy: 0.7319\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 7s 276us/sample - loss: 0.5472 - accuracy: 0.7330\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 7s 279us/sample - loss: 0.5474 - accuracy: 0.7322\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 7s 262us/sample - loss: 0.5470 - accuracy: 0.7326\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 7s 258us/sample - loss: 0.5472 - accuracy: 0.7318\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 7s 263us/sample - loss: 0.5469 - accuracy: 0.7326\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 7s 262us/sample - loss: 0.5469 - accuracy: 0.7326\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 7s 261us/sample - loss: 0.5473 - accuracy: 0.7323\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 7s 268us/sample - loss: 0.5468 - accuracy: 0.7324\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 7s 263us/sample - loss: 0.5472 - accuracy: 0.7333\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 7s 261us/sample - loss: 0.5468 - accuracy: 0.7329\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 6s 251us/sample - loss: 0.5471 - accuracy: 0.7326\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 7s 267us/sample - loss: 0.5470 - accuracy: 0.7329\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 7s 262us/sample - loss: 0.5470 - accuracy: 0.7334\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 7s 264us/sample - loss: 0.5472 - accuracy: 0.7332\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 7s 267us/sample - loss: 0.5467 - accuracy: 0.7322\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 7s 256us/sample - loss: 0.5469 - accuracy: 0.7327\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 7s 259us/sample - loss: 0.5470 - accuracy: 0.7328\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 7s 269us/sample - loss: 0.5469 - accuracy: 0.7325\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 7s 275us/sample - loss: 0.5467 - accuracy: 0.7322\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 7s 275us/sample - loss: 0.5468 - accuracy: 0.7325\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 7s 280us/sample - loss: 0.5468 - accuracy: 0.7331\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 7s 275us/sample - loss: 0.5467 - accuracy: 0.7332\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 7s 276us/sample - loss: 0.5468 - accuracy: 0.7326\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 7s 272us/sample - loss: 0.5465 - accuracy: 0.7327\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 7s 276us/sample - loss: 0.5469 - accuracy: 0.7325\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 7s 275us/sample - loss: 0.5471 - accuracy: 0.7322\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 7s 272us/sample - loss: 0.5468 - accuracy: 0.7323\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 7s 281us/sample - loss: 0.5467 - accuracy: 0.7327\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 7s 278us/sample - loss: 0.5466 - accuracy: 0.7322\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 7s 266us/sample - loss: 0.5470 - accuracy: 0.7327\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 7s 270us/sample - loss: 0.5467 - accuracy: 0.7324\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 1s - loss: 0.7164 - accuracy: 0.4668\n",
      "Loss: 0.7141006438238627, Accuracy: 0.46682214736938477\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unsure if i needed to reset the nn as the loss started where the last one left off but the \n",
    "# accuracy dropped pointing to over fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 6)                 288       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 313\n",
      "Trainable params: 313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  6\n",
    "hidden_nodes_layer2 = 3\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 11s 431us/sample - loss: 0.6887 - accuracy: 0.6085\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 7s 264us/sample - loss: 0.6180 - accuracy: 0.6652\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 7s 258us/sample - loss: 0.5920 - accuracy: 0.7216\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 7s 274us/sample - loss: 0.5786 - accuracy: 0.7241\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 7s 258us/sample - loss: 0.5725 - accuracy: 0.7248\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 7s 268us/sample - loss: 0.5684 - accuracy: 0.7247 - - ETA: 0s - loss: 0.5676 - ac\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 7s 284us/sample - loss: 0.5665 - accuracy: 0.7245\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 7s 267us/sample - loss: 0.5652 - accuracy: 0.7259\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 7s 283us/sample - loss: 0.5642 - accuracy: 0.7261\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 7s 274us/sample - loss: 0.5634 - accuracy: 0.7269\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 7s 268us/sample - loss: 0.5625 - accuracy: 0.7281\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 7s 274us/sample - loss: 0.5623 - accuracy: 0.7275\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 7s 283us/sample - loss: 0.5621 - accuracy: 0.7282\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 7s 274us/sample - loss: 0.5616 - accuracy: 0.7275\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 7s 274us/sample - loss: 0.5615 - accuracy: 0.7282\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 7s 281us/sample - loss: 0.5608 - accuracy: 0.7284\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 7s 272us/sample - loss: 0.5606 - accuracy: 0.7285\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - ETA: 0s - loss: 0.5605 - accuracy: 0.72 - 7s 281us/sample - loss: 0.5604 - accuracy: 0.7281\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 7s 273us/sample - loss: 0.5602 - accuracy: 0.7282\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 7s 279us/sample - loss: 0.5598 - accuracy: 0.7282\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 7s 268us/sample - loss: 0.5598 - accuracy: 0.7285\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 7s 271us/sample - loss: 0.5590 - accuracy: 0.7287\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 7s 279us/sample - loss: 0.5587 - accuracy: 0.7289\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 7s 275us/sample - loss: 0.5582 - accuracy: 0.7289\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 7s 275us/sample - loss: 0.5583 - accuracy: 0.7301\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 7s 274us/sample - loss: 0.5580 - accuracy: 0.7302\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 7s 269us/sample - loss: 0.5579 - accuracy: 0.7296\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 7s 274us/sample - loss: 0.5577 - accuracy: 0.7307\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 7s 271us/sample - loss: 0.5577 - accuracy: 0.7300\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 7s 275us/sample - loss: 0.5576 - accuracy: 0.7298\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 7s 269us/sample - loss: 0.5574 - accuracy: 0.7295\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 7s 267us/sample - loss: 0.5570 - accuracy: 0.7301\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 7s 273us/sample - loss: 0.5572 - accuracy: 0.7303\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 7s 267us/sample - loss: 0.5569 - accuracy: 0.7296\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 7s 266us/sample - loss: 0.5569 - accuracy: 0.7296\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 7s 268us/sample - loss: 0.5568 - accuracy: 0.7301\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 7s 271us/sample - loss: 0.5565 - accuracy: 0.7302\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 7s 257us/sample - loss: 0.5565 - accuracy: 0.7308\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 7s 264us/sample - loss: 0.5565 - accuracy: 0.7298\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 7s 253us/sample - loss: 0.5562 - accuracy: 0.7301\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 7s 267us/sample - loss: 0.5561 - accuracy: 0.7314\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 7s 255us/sample - loss: 0.5561 - accuracy: 0.7305\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 7s 256us/sample - loss: 0.5561 - accuracy: 0.7315\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 6s 251us/sample - loss: 0.5559 - accuracy: 0.7316\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 7s 257us/sample - loss: 0.5558 - accuracy: 0.7314\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 7s 259us/sample - loss: 0.5556 - accuracy: 0.7311\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 7s 259us/sample - loss: 0.5557 - accuracy: 0.7313\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 7s 258us/sample - loss: 0.5556 - accuracy: 0.7305\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 7s 259us/sample - loss: 0.5555 - accuracy: 0.7304\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 6s 248us/sample - loss: 0.5555 - accuracy: 0.7317\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next look to use basid neural net again and if not look to cut down on features to feed into nets \n",
    "# to see if I can get it any closer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 2s - loss: 0.7450 - accuracy: 0.5332\n",
      "Loss: 0.7514321748299779, Accuracy: 0.5331778526306152\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# looks like same accuracy as single hidden layer, work to be done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 384       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 445\n",
      "Trainable params: 445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 6\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 20s 771us/sample - loss: 0.6339 - accuracy: 0.6432\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 11s 411us/sample - loss: 0.5753 - accuracy: 0.7142\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 11s 440us/sample - loss: 0.5613 - accuracy: 0.7230\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 12s 476us/sample - loss: 0.5557 - accuracy: 0.7247\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 11s 423us/sample - loss: 0.5533 - accuracy: 0.7281\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 10s 372us/sample - loss: 0.5517 - accuracy: 0.7306\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 11s 431us/sample - loss: 0.5506 - accuracy: 0.7313\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 11s 411us/sample - loss: 0.5500 - accuracy: 0.7315- loss: 0\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 10s 406us/sample - loss: 0.5492 - accuracy: 0.7317\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 11s 418us/sample - loss: 0.5490 - accuracy: 0.7314- loss: 0\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 12s 451us/sample - loss: 0.5483 - accuracy: 0.7314\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 11s 440us/sample - loss: 0.5481 - accuracy: 0.7322\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 10s 389us/sample - loss: 0.5477 - accuracy: 0.7328\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 10s 383us/sample - loss: 0.5476 - accuracy: 0.7321\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 10s 405us/sample - loss: 0.5472 - accuracy: 0.7317- loss: 0\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 10s 379us/sample - loss: 0.5471 - accuracy: 0.7330\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 9s 365us/sample - loss: 0.5471 - accuracy: 0.7329\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 11s 420us/sample - loss: 0.5465 - accuracy: 0.7339\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 11s 422us/sample - loss: 0.5466 - accuracy: 0.7326\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 11s 434us/sample - loss: 0.5463 - accuracy: 0.7324\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 11s 419us/sample - loss: 0.5462 - accuracy: 0.7327\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 10s 381us/sample - loss: 0.5462 - accuracy: 0.7320\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 10s 390us/sample - loss: 0.5463 - accuracy: 0.7321\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 9s 366us/sample - loss: 0.5461 - accuracy: 0.7341\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 10s 395us/sample - loss: 0.5459 - accuracy: 0.7333\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 10s 377us/sample - loss: 0.5459 - accuracy: 0.7336\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 11s 409us/sample - loss: 0.5459 - accuracy: 0.7336\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 12s 448us/sample - loss: 0.5458 - accuracy: 0.7336\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 10s 405us/sample - loss: 0.5456 - accuracy: 0.7335\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 10s 404us/sample - loss: 0.5457 - accuracy: 0.7343\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 10s 393us/sample - loss: 0.5455 - accuracy: 0.7347\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 11s 418us/sample - loss: 0.5450 - accuracy: 0.7345- loss: 0.5448 - accuracy\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 11s 443us/sample - loss: 0.5452 - accuracy: 0.7337\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 11s 434us/sample - loss: 0.5451 - accuracy: 0.7333\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 11s 423us/sample - loss: 0.5452 - accuracy: 0.7336\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 10s 392us/sample - loss: 0.5450 - accuracy: 0.7336\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 11s 432us/sample - loss: 0.5449 - accuracy: 0.7354\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 11s 439us/sample - loss: 0.5446 - accuracy: 0.7343\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 11s 433us/sample - loss: 0.5446 - accuracy: 0.7348\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 10s 399us/sample - loss: 0.5447 - accuracy: 0.7348\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 10s 401us/sample - loss: 0.5450 - accuracy: 0.7348\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 11s 415us/sample - loss: 0.5447 - accuracy: 0.7351\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 11s 413us/sample - loss: 0.5448 - accuracy: 0.7352\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 11s 416us/sample - loss: 0.5448 - accuracy: 0.7342\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 10s 391us/sample - loss: 0.5442 - accuracy: 0.7340\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 10s 383us/sample - loss: 0.5443 - accuracy: 0.7353\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 10s 395us/sample - loss: 0.5442 - accuracy: 0.7339\n",
      "Epoch 48/50\n",
      " 5440/25724 [=====>........................] - ETA: 8s - loss: 0.5507 - accuracy: 0.7305  "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
